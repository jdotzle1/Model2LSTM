#!/usr/bin/env python3
"""
Test Monthly Processing Integration with Enhanced Statistics

This test validates that the enhanced statistics collection integrates
properly with the monthly processing pipeline.
"""

import sys
import os
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from pathlib import Path
import tempfile
import json

# Add project root to path
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

def create_realistic_test_data():
    """Create more realistic test data that might generate some wins"""
    
    import pytz
    
    # Create 500 bars of test data (more data for potential wins)
    n_bars = 500
    
    # Create timestamps in Central Time during RTH
    central_tz = pytz.timezone('US/Central')
    start_time_ct = central_tz.localize(datetime(2024, 3, 1, 8, 0, 0))  # 08:00 CT
    
    # Convert to UTC for storage
    timestamps = []
    for i in range(n_bars):
        ct_time = start_time_ct + timedelta(seconds=i)
        utc_time = ct_time.astimezone(pytz.UTC)
        timestamps.append(utc_time)
    
    # Generate more realistic price data with trends that might create wins
    base_price = 4750.0
    data = []
    
    # Create some trending periods to increase win probability
    trend_changes = [100, 200, 300, 400]  # Points where trend changes
    current_trend = 0.02  # Start with slight uptrend
    
    for i, ts in enumerate(timestamps):
        # Change trend at certain points
        if i in trend_changes:
            current_trend = np.random.choice([-0.05, -0.02, 0.02, 0.05])  # Random trend
        
        # Create price with trend + noise
        if i == 0:
            price = base_price
        else:
            price = data[i-1]['close'] + current_trend + np.random.normal(0, 0.3)
        
        # Create valid OHLC relationships
        open_price = round(price + np.random.uniform(-0.25, 0.25), 2)
        close_price = round(price + current_trend + np.random.uniform(-0.25, 0.25), 2)
        
        # Ensure high is at least as high as open and close
        high_price = round(max(open_price, close_price) + np.random.uniform(0, 1.0), 2)
        
        # Ensure low is at most as low as open and close
        low_price = round(min(open_price, close_price) - np.random.uniform(0, 1.0), 2)
        
        data.append({
            'timestamp': ts,
            'open': open_price,
            'high': high_price,
            'low': low_price,
            'close': close_price,
            'volume': np.random.randint(500, 3000)
        })
    
    return pd.DataFrame(data)

def test_monthly_processing_integration():
    """Test the integration of enhanced statistics with monthly processing"""
    
    print("üß™ Testing Monthly Processing Integration with Enhanced Statistics")
    print("=" * 70)
    
    try:
        # Import required modules
        from src.data_pipeline.weighted_labeling import WeightedLabelingEngine, OutputDataFrame
        
        print("‚úÖ Successfully imported required modules")
        
    except ImportError as e:
        print(f"‚ùå Import failed: {e}")
        return False
    
    # Test 1: Create and process realistic test data
    print("\nüìä Test 1: Creating and processing realistic test data")
    
    try:
        df = create_realistic_test_data()
        print(f"   ‚úÖ Created realistic test data: {len(df)} rows")
        print(f"   üìÖ Date range: {df['timestamp'].min()} to {df['timestamp'].max()}")
        print(f"   üí∞ Price range: ${df['close'].min():.2f} - ${df['close'].max():.2f}")
        
        # Process with weighted labeling
        engine = WeightedLabelingEngine()
        df_labeled = engine.process_dataframe(df, validate_performance=False)
        print(f"   ‚úÖ Weighted labeling complete: {len(df_labeled.columns)} columns")
        
        # Check if we got any wins (more realistic with trending data)
        label_cols = [col for col in df_labeled.columns if col.startswith('label_')]
        total_wins = sum(df_labeled[col].sum() for col in label_cols)
        print(f"   üéØ Total wins across all modes: {total_wins}")
        
    except Exception as e:
        print(f"   ‚ùå Data processing failed: {e}")
        import traceback
        traceback.print_exc()
        return False
    
    # Test 2: Simulate monthly processing statistics collection
    print("\nüìà Test 2: Simulating monthly processing statistics collection")
    
    try:
        # Simulate the data that would be collected during monthly processing
        processing_start_time = datetime.now()
        
        # Simulate processing stages
        stage_times = {
            'dbn_conversion': 45.2,
            'data_cleaning': 12.8,
            'rth_filtering': 8.5,
            'weighted_labeling': 180.3,
            'feature_engineering': 145.7,
            'upload': 25.1
        }
        
        total_processing_time = sum(stage_times.values()) / 60  # Convert to minutes
        
        # Simulate memory usage
        memory_usage = {
            'dbn_conversion': 1200.0,
            'data_cleaning': 1150.0,
            'rth_filtering': 1100.0,
            'weighted_labeling': 2800.0,
            'feature_engineering': 3200.0,
            'upload': 1800.0
        }
        
        peak_memory = max(memory_usage.values())
        final_memory = memory_usage['upload']
        
        # Simulate rollover events
        rollover_events = [
            {
                'timestamp': datetime(2024, 3, 1, 10, 15, 30),
                'price_gap': 28.5,
                'bars_affected': 6,
                'gap_direction': 'up'
            },
            {
                'timestamp': datetime(2024, 3, 1, 12, 45, 15),
                'price_gap': 22.0,
                'bars_affected': 6,
                'gap_direction': 'down'
            }
        ]
        
        # Simulate feature quality metrics
        feature_quality = {
            'features_generated': 43,
            'expected_features': 43,
            'feature_completeness': 100.0,
            'avg_nan_percentage': 18.5,
            'max_nan_percentage': 34.2,
            'high_nan_features': ['volume_slope_5s', 'momentum_consistency'],
            'features_with_outliers': ['bar_range', 'relative_bar_size'],
            'suspicious_ranges': [],
            'quality_score': 0.78
        }
        
        print(f"   ‚úÖ Simulated processing metrics:")
        print(f"      Total processing time: {total_processing_time:.1f} minutes")
        print(f"      Peak memory usage: {peak_memory:.1f} MB")
        print(f"      Rollover events: {len(rollover_events)}")
        print(f"      Feature quality score: {feature_quality['quality_score']:.2f}")
        
    except Exception as e:
        print(f"   ‚ùå Statistics simulation failed: {e}")
        return False
    
    # Test 3: Test enhanced OutputDataFrame.get_statistics() with simulated data
    print("\nüìä Test 3: Testing enhanced statistics with simulated monthly data")
    
    try:
        output_data = OutputDataFrame(df_labeled, ['timestamp', 'open', 'high', 'low', 'close', 'volume'])
        
        # Prepare comprehensive processing metrics
        processing_metrics = {
            'processing_time_minutes': total_processing_time,
            'memory_peak_mb': peak_memory,
            'memory_final_mb': final_memory,
            'rows_per_minute': len(df_labeled) / total_processing_time,
            'processing_efficiency_score': min(1.0, (len(df_labeled) / total_processing_time) / 1000),
            'stage_times': stage_times,
            'slowest_stage': max(stage_times.items(), key=lambda x: x[1])[0],
            'slowest_stage_time': max(stage_times.values())
        }
        
        # Get comprehensive enhanced statistics
        enhanced_stats = output_data.get_statistics(
            processing_metrics=processing_metrics,
            rollover_events=rollover_events,
            feature_quality=feature_quality
        )
        
        print(f"   ‚úÖ Enhanced statistics collected successfully")
        
        # Validate the comprehensive statistics structure
        dataset_summary = enhanced_stats.get('dataset_summary', {})
        
        # Validate processing metrics
        proc_metrics = dataset_summary.get('processing_metrics', {})
        assert proc_metrics.get('processing_time_minutes') == total_processing_time
        assert proc_metrics.get('memory_peak_mb') == peak_memory
        assert proc_metrics.get('slowest_stage') == 'weighted_labeling'
        print(f"   ‚úÖ Processing metrics validation passed")
        
        # Validate rollover statistics
        rollover_stats = dataset_summary.get('rollover_statistics', {})
        assert rollover_stats.get('total_rollover_events') == 2
        assert rollover_stats.get('avg_price_gap') == 25.25  # (28.5 + 22.0) / 2
        assert rollover_stats.get('bars_excluded_rollover') == 12  # 6 + 6
        print(f"   ‚úÖ Rollover statistics validation passed")
        
        # Validate feature quality metrics
        feature_stats = dataset_summary.get('feature_quality', {})
        assert feature_stats.get('features_generated') == 43
        assert feature_stats.get('feature_quality_score') == 0.78
        assert feature_stats.get('high_nan_features_count') == 2
        print(f"   ‚úÖ Feature quality metrics validation passed")
        
        # Validate mode statistics
        mode_count = 0
        for mode_name in ['low_vol_long', 'normal_vol_long', 'high_vol_long', 
                         'low_vol_short', 'normal_vol_short', 'high_vol_short']:
            if mode_name in enhanced_stats:
                mode_stats = enhanced_stats[mode_name]
                assert 'win_rate' in mode_stats
                assert 'avg_weight' in mode_stats
                assert 'validation_passed' in mode_stats
                mode_count += 1
        
        assert mode_count == 6
        print(f"   ‚úÖ All 6 trading mode statistics validated")
        
    except Exception as e:
        print(f"   ‚ùå Enhanced statistics test failed: {e}")
        import traceback
        traceback.print_exc()
        return False
    
    # Test 4: Test JSON serialization for S3 storage
    print("\nüíæ Test 4: Testing JSON serialization for S3 storage")
    
    try:
        # Create a simplified statistics object for JSON serialization
        monthly_stats_dict = {
            'month_str': '2024-03',
            'processing_date': datetime.now().isoformat(),
            'overall_quality_score': 0.82,
            'requires_reprocessing': False,
            'processing_successful': True,
            'total_rollover_events': len(rollover_events),
            'rollover_affected_percentage': (12 / len(df_labeled)) * 100,
            'processing_metrics': processing_metrics,
            'rollover_statistics': rollover_stats,
            'feature_quality': feature_stats,
            'mode_statistics': {
                mode_name: enhanced_stats[mode_name] 
                for mode_name in enhanced_stats 
                if mode_name != 'dataset_summary'
            }
        }
        
        # Test JSON serialization
        json_str = json.dumps(monthly_stats_dict, default=str, indent=2)
        
        # Test deserialization
        json_data = json.loads(json_str)
        
        assert json_data['month_str'] == '2024-03'
        assert json_data['total_rollover_events'] == 2
        assert 'processing_metrics' in json_data
        assert 'mode_statistics' in json_data
        
        print(f"   ‚úÖ JSON serialization successful")
        print(f"   üìÑ JSON size: {len(json_str)} characters")
        
        # Save test output
        with tempfile.NamedTemporaryFile(mode='w', suffix='_monthly_stats.json', delete=False) as f:
            f.write(json_str)
            json_file = f.name
        
        print(f"   üíæ Test JSON saved to: {json_file}")
        
    except Exception as e:
        print(f"   ‚ùå JSON serialization test failed: {e}")
        import traceback
        traceback.print_exc()
        return False
    
    # Test 5: Validate upload metadata structure
    print("\nüì§ Test 5: Testing upload metadata structure")
    
    try:
        # Simulate the enhanced metadata that would be uploaded to S3
        enhanced_metadata = {
            'source': 'monthly_processing_pipeline_enhanced',
            'month': '2024-03',
            'processing_date': datetime.now().strftime("%Y%m%d_%H%M%S"),
            'file_size_mb': '125.7',
            'row_count': str(len(df_labeled)),
            'column_count': str(len(df_labeled.columns)),
            'label_columns_count': '6',
            'weight_columns_count': '6',
            'feature_columns_count': '43',
            'pipeline_version': '3.0_enhanced_statistics',
            'overall_quality_score': str(monthly_stats_dict['overall_quality_score']),
            'requires_reprocessing': str(monthly_stats_dict['requires_reprocessing']),
            'processing_successful': str(monthly_stats_dict['processing_successful']),
            'total_rollover_events': str(monthly_stats_dict['total_rollover_events']),
            'rollover_affected_percentage': str(monthly_stats_dict['rollover_affected_percentage']),
            'processing_time_minutes': str(processing_metrics['processing_time_minutes']),
            'peak_memory_mb': str(processing_metrics['memory_peak_mb']),
            'rows_per_minute': str(processing_metrics['rows_per_minute']),
            'feature_quality_score': str(feature_quality['quality_score']),
            'features_generated': str(feature_quality['features_generated'])
        }
        
        # Validate metadata structure
        required_fields = [
            'source', 'month', 'processing_date', 'overall_quality_score',
            'processing_time_minutes', 'peak_memory_mb', 'total_rollover_events',
            'feature_quality_score', 'features_generated'
        ]
        
        for field in required_fields:
            assert field in enhanced_metadata, f"Missing required field: {field}"
        
        print(f"   ‚úÖ Enhanced metadata structure validated")
        print(f"   üìä Metadata fields: {len(enhanced_metadata)}")
        print(f"   üéØ Key metrics included:")
        print(f"      Quality score: {enhanced_metadata['overall_quality_score']}")
        print(f"      Processing time: {enhanced_metadata['processing_time_minutes']} min")
        print(f"      Peak memory: {enhanced_metadata['peak_memory_mb']} MB")
        print(f"      Rollover events: {enhanced_metadata['total_rollover_events']}")
        
    except Exception as e:
        print(f"   ‚ùå Metadata validation failed: {e}")
        import traceback
        traceback.print_exc()
        return False
    
    print("\nüéâ All Monthly Processing Integration Tests Passed!")
    print("=" * 70)
    
    # Summary
    print("\nüìã Integration Test Summary:")
    print("‚úÖ Enhanced OutputDataFrame.get_statistics() with comprehensive metrics")
    print("‚úÖ Processing time and memory usage tracking integration")
    print("‚úÖ Rollover event tracking and statistics per month")
    print("‚úÖ Feature quality metrics and data quality flags")
    print("‚úÖ JSON serialization for S3 statistics storage")
    print("‚úÖ Enhanced S3 metadata structure for upload_monthly_results()")
    
    return True

if __name__ == "__main__":
    success = test_monthly_processing_integration()
    if success:
        print("\nüéØ Task 3.4 Monthly Processing Integration: COMPLETE")
        print("Enhanced monthly statistics collection is fully integrated!")
    else:
        print("\n‚ùå Task 3.4 Monthly Processing Integration: FAILED")
        print("Please review the errors above and fix the issues.")
    
    sys.exit(0 if success else 1)